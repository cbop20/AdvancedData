{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 21: Estimating Missing Data\n",
    "***\n",
    "\n",
    "In this notebook, we will dive deeper into the problem of estimating missing ratings/data. Specifically, we will conduct some **preprocessing** on our data matrix, which can account for differences in how different users rate different items. Some users tend to be kind raters, and some will be stingier with those 5-star reviews. Normalizing our utility matrix before performing the UV decomposition on it will account for these differences.\n",
    "\n",
    "We'll need numpy for this notebook, so let's load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Exercise 1: Preprocessing the data matrix\n",
    "\n",
    "In class we performed a few iterations to find the UV decomposition of the following matrix, where the rows correspond to different users, and the columns correspond to different items. The elements of the matrix are the users' ratings for each item. There two unknown values:\n",
    "* User 3's rating for Item 2, and\n",
    "* User 6's rating for Item 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([[5,2,4,4,3],\n",
    "              [3,1,2,4,1],\n",
    "              [2,np.nan,3,1,4],\n",
    "              [2,5,4,3,5],\n",
    "              [2,5,4,3,5],\n",
    "              [4,4,5,4,np.nan]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We suggested in class that **preprocessing** the data matrix would lead to better results, by accounting for differences in the ways different users tend to rate items, and differences in item ratings. Some of the possible methods for preprocessing are:\n",
    "* Subtract from each non-blank element $m_{ij}$ the average rating of user $i$\n",
    "* Subtract from each non-blank element in column $j$ the average rating of item $j$\n",
    "* Do both of these, in either order\n",
    "* From element $m_{ij}$ subtract $\\frac{1}{2} \\times$ (the average of user $i$ + the average of item $j$)\n",
    "\n",
    "Let's shoot for the stars and subtract from each non-missing element $m_{ij}$ the average rating of user $i$, then subtract from that intermediate matrix the average rating of item $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "user_means = np.zeros(M.shape[0])\n",
    "item_means = np.zeros(M.shape[1])\n",
    "\n",
    "# TODO -- compute the mean rating for each user (not including blanks)\n",
    "user_means = np.zeros(M.shape[0])  # <-- modify this!\n",
    "\n",
    "# normalize M first by subtracting from each non-blank element that user's mean rating\n",
    "M_norm = M.copy()\n",
    "for u in range(len(user_means)):\n",
    "    M_norm[u,:] -= user_means[u]\n",
    "\n",
    "# TODO -- compute the mean rating for each user (not including blanks)\n",
    "item_means = np.zeros(M.shape[1])  # <-- modify this!\n",
    "\n",
    "# normalize M once more by subtracting from each non-blank element that item's mean rating\n",
    "for i in range(len(item_means)):\n",
    "    M_norm[:,i] -= item_means[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that whatever we subtract off from each element of the matrix during preprocessing, we need to *add that back in* when estimating the missing values after our UV decomposition. So **go back** to the code cell above and **add in** a matrix that is of the same size as $M$, whose elements are the total amount that we subtracted off from each element of $M$ during the preprocessing normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.  2.  4.  4.  3.]\n",
      " [ 3.  1.  2.  4.  1.]\n",
      " [ 2. nan  3.  1.  4.]\n",
      " [ 2.  5.  4.  3.  5.]\n",
      " [ 2.  5.  4.  3.  5.]\n",
      " [ 4.  4.  5.  4. nan]]\n",
      "[[ 5.  2.  4.  4.  3.]\n",
      " [ 3.  1.  2.  4.  1.]\n",
      " [ 2. nan  3.  1.  4.]\n",
      " [ 2.  5.  4.  3.  5.]\n",
      " [ 2.  5.  4.  3.  5.]\n",
      " [ 4.  4.  5.  4. nan]]\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION:\n",
    "\n",
    "# initialize\n",
    "user_means = np.zeros(M.shape[0])\n",
    "item_means = np.zeros(M.shape[1])\n",
    "\n",
    "# added for un-normalizing to make rating estimates:\n",
    "M_sub = np.zeros(M.shape)\n",
    "\n",
    "# TODO -- compute the mean rating for each user (not including blanks)\n",
    "user_means = np.nanmean(M, axis=1)\n",
    "\n",
    "# normalize M first by subtracting from each non-blank element that user's mean rating\n",
    "M_norm = M.copy()\n",
    "for u in range(len(user_means)):\n",
    "    M_norm[u,:] -= user_means[u]\n",
    "    M_sub[u,:] -= user_means[u]\n",
    "\n",
    "# TODO -- compute the mean rating for each user (not including blanks)\n",
    "item_means = np.nanmean(M_norm, axis=0)\n",
    "\n",
    "# normalize M once more by subtracting from each non-blank element that item's mean rating\n",
    "for i in range(len(item_means)):\n",
    "    M_norm[:,i] -= item_means[i]\n",
    "    M_sub[:,i] -= item_means[i]\n",
    "    \n",
    "print(M)\n",
    "print(M_norm-M_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we currently have $M=M_{norm}-M_{sub}$, and we'll use $M_{norm}$ for our UV fitting.\n",
    "\n",
    "**Reflect:** Why did we not compute the user and item rating means at the same time? Why did we have to normalize by the user ratings first, *then* compute the mean item ratings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Exercise 2: U and V!\n",
    "\n",
    "Let's find the UV decomposition of M (`M_norm`) using 2 dimensional vectors.  Per the slides, we need to alternatingly compute:\n",
    "\n",
    "\n",
    "$$x=u_{rs}=\\frac{\\sum_j v_{sj} (m_{rj} - \\sum_{k \\ne s} u_{rk}v_{kj} )}{\\sum_j v_{sj}^2}$$\n",
    "\n",
    "$$y=v_{rs}=\\frac{\\sum_i u_{ir} (m_{is} - \\sum_{k \\ne r} u_{ik}v_{ks} )}{\\sum_i u_{ir}^2}$$\n",
    "\n",
    "for $x$ in the $U$ matrix and $y$ in the $V$ matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a couple of \"easy\" updates, and initialize U and V as all-ones, then update `u[0,0]` and `v[0,0]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.75833333 -1.47        0.09166667  0.59166667 -1.02      ]\n",
      " [ 1.15833333 -1.07       -0.50833333  1.99166667 -1.62      ]\n",
      " [-0.14166667         nan  0.19166667 -1.30833333  1.08      ]\n",
      " [-1.44166667  1.33       -0.10833333 -0.60833333  0.78      ]\n",
      " [-1.44166667  1.33       -0.10833333 -0.60833333  0.78      ]\n",
      " [ 0.10833333 -0.12        0.44166667 -0.05833333         nan]]\n",
      "-1.0096666666666667 -1.2499524456380038\n",
      "[[ 2.26203532 -0.00966667 -0.00966667 -0.00966667 -0.00966667]\n",
      " [-0.24995245  2.          2.          2.          2.        ]\n",
      " [-0.24995245  2.          2.          2.          2.        ]\n",
      " [-0.24995245  2.          2.          2.          2.        ]\n",
      " [-0.24995245  2.          2.          2.          2.        ]\n",
      " [-0.24995245  2.          2.          2.          2.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Initialize U and V\n",
    "d=2\n",
    "U = np.ones((M.shape[0],d))\n",
    "V= np.ones((d,M.shape[1]))\n",
    "#Update U[0,0]\n",
    "r=0\n",
    "s=0\n",
    "U[r,s]=np.sum([V[s,j]*(M_norm[r,j]-np.sum(U[r,:]*V[:,j])+U[r,s]*V[s,j])  for j in range(M.shape[1])])/np.sum(V[0,:]**2)\n",
    "V[r,s]=np.sum([U[i,r]*(M_norm[i,s]-np.sum(U[i,:]*V[:,s])+U[i,r]*V[r,s])  for i in range(M.shape[0])])/np.sum(U[:,0]**2)\n",
    "\n",
    "print(M_norm)\n",
    "print(U[0,0],V[0,0])\n",
    "print(np.matmul(U,V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.00966667  1.        ]\n",
      " [-1.00966667  1.        ]\n",
      " [-0.83566667  0.63286667]\n",
      " [-1.00966667  1.        ]\n",
      " [-1.00966667  1.        ]\n",
      " [-0.72566667  0.65486667]]\n",
      "[[0.9521419  0.84482508 0.9809326  0.90493269 0.89680877]\n",
      " [0.99723803 0.79821093 0.97813864 1.04854499 0.76608305]]\n"
     ]
    }
   ],
   "source": [
    "##Now set it up as a loop, running down U and V in order (by whichever dimension first)\n",
    "d=2\n",
    "U = np.ones((M.shape[0],d))\n",
    "V= np.ones((d,M.shape[1]))\n",
    "\n",
    "\n",
    "for r in range(M.shape[0]):\n",
    "    for s in range(d):\n",
    "        U[r,s]=np.nansum([V[s,j]*(M_norm[r,j]-np.sum(U[r,:]*V[:,j])+U[r,s]*V[s,j])  for j in range(M.shape[1])])/np.nansum(V[s,:]**2)\n",
    "for s in range(M.shape[1]):\n",
    "    for r in range(d):\n",
    "        V[r,s]=np.nansum([U[i,r]*(M_norm[i,s]-np.sum(U[i,:]*V[:,s])+U[i,r]*V[r,s])  for i in range(M.shape[0])])/np.nansum(U[:,r]**2)\n",
    "\n",
    "print(U)\n",
    "print(V)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've done a step!  Let's see how we're doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Exercise 3: Back to M\n",
    "\n",
    "To go back to doing inference in M, we have to do 2 things: compute $P=UV$, then undo our normalization step.  The final result can be compared to M!\n",
    "\n",
    "Recall that our current scoring metric is RMSE:\n",
    "\n",
    "$$\\sqrt{\\frac{1}{n} \\sum_{i,j} (M_{i,j} - P_{i,j})^2} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.27755875 3.41521921 3.89605703 3.54319795 3.88060514]\n",
      " [1.87755875 2.01521921 2.49605703 2.14319795 2.48060514]\n",
      " [1.97711212 2.16916893 2.607632   2.21570042 2.65539524]\n",
      " [3.47755875 3.61521921 4.09605703 3.74319795 4.08060514]\n",
      " [3.47755875 3.61521921 4.09605703 3.74319795 4.08060514]\n",
      " [3.85378697 4.02966033 4.48705363 4.08831101 4.52089803]]\n",
      "[[ 5.  2.  4.  4.  3.]\n",
      " [ 3.  1.  2.  4.  1.]\n",
      " [ 2. nan  3.  1.  4.]\n",
      " [ 2.  5.  4.  3.  5.]\n",
      " [ 2.  5.  4.  3.  5.]\n",
      " [ 4.  4.  5.  4. nan]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0157677537544327"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P=np.matmul(U,V)\n",
    "\n",
    "#Put M_sub into P\n",
    "P_unnorm= P-M_sub\n",
    "print(P_unnorm)\n",
    "print(M)\n",
    "def RMSE(M1, M2):\n",
    "    rmse=np.sqrt(np.nansum((M1-M2)**2)/(M1.shape[0]*M1.shape[1]-np.sum(np.isnan(M1))))\n",
    "    return rmse\n",
    "\n",
    "RMSE(M,P_unnorm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to say that we're doing great after one iteration, but we could at least check that we've done better than the RMSE from the all-ones initializations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.242624817357681\n",
      "2.242624817357681\n"
     ]
    }
   ],
   "source": [
    "U = np.ones((M.shape[0],d))\n",
    "V= np.ones((d,M.shape[1]))\n",
    "\n",
    "P=np.matmul(U,V)\n",
    "P_unnorm= P-M_sub\n",
    "\n",
    "print(RMSE(M,P_unnorm))\n",
    "print(RMSE(M_norm, P))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we could (and probably should!) also save a little time by just computing the RMSE of $P$ compared directly to $M_{norm}$.  \n",
    "\n",
    "\n",
    "**Contemplate**: how does doing the RMSE calculation change depending on which one we use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Exercise 4: Bring Order to the Galaxy\n",
    "\n",
    "Are we convinced that order really matters?  Repeat exercise 2, but instead of looping in a structured format over the rows and columns, create a random ordering of the $u_{rs}$ indices and another random ordering of the $v_{rs}$ indices, then pass those into the inside of your loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize U and V again\n",
    "U = np.ones((M.shape[0],d))\n",
    "V= np.ones((d,M.shape[0]))\n",
    "indices_list=[(x, y) for x in range(M.shape[0]) for y in range(d)]\n",
    "\n",
    "#randomize the u's update order\n",
    "U_index_order = # TODO\n",
    "#randomize the v's update order\n",
    "U_index_order = # TODO\n",
    "\n",
    "for \n",
    "    U[u_index_order]= # TODO\n",
    "    V[v_index_order]= # TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any better?  Any different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P=np.matmul(U,V)\n",
    "#Put M_sub into P\n",
    "P_unnorm= # TODO\n",
    "RMSE(M,P_unnorm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
