{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a/ id='top'></a>\n",
    "\n",
    "# CSCI4022 Homework 2; Minhashing\n",
    "\n",
    "## Due Friday, February 4 at 11:59 pm to Canvas and Gradescope\n",
    "\n",
    "#### Submit this file as a .ipynb with *all cells compiled and run* to the associated dropbox.\n",
    "\n",
    "***\n",
    "\n",
    "Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  Remember that you are encouraged to discuss the problems with your classmates, but **you must write all code and solutions on your own**.\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Any relevant data sets should be available on Canvas. To make life easier on the graders if they need to run your code, do not change the relative path names here. Instead, move the files around on your computer.\n",
    "- If you're not familiar with typesetting math directly into Markdown then by all means, do your work on paper first and then typeset it later.  Here is a [reference guide](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) linked on Canvas on writing math in Markdown. **All** of your written commentary, justifications and mathematical work should be in Markdown.  I also recommend the [wikibook](https://en.wikibooks.org/wiki/LaTeX) for LaTex.\n",
    "- Because you can technically evaluate notebook cells is a non-linear order, it's a good idea to do **Kernel $\\rightarrow$ Restart & Run All** as a check before submitting your solutions.  That way if we need to run your code you will know that it will work as expected. \n",
    "- It is **bad form** to make your reader interpret numerical output from your code.  If a question asks you to compute some value from the data you should show your code output **AND** write a summary of the results in Markdown directly below your code. \n",
    "- 45 points of this assignment are in problems.  The remaining 5 are for neatness, style, and overall exposition of both code and text.\n",
    "- This probably goes without saying, but... For any question that asks you to calculate something, you **must show all work and justify your answers to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit. \n",
    "- There is *not a prescribed API* for these problems.  You may answer coding questions with whatever syntax or object typing you deem fit.  Your evaluation will primarily live in the clarity of how well you present your final results, so don't skip over any interpretations!  Your code should still be commented and readable to ensure you followed the given course algorithm.\n",
    "- There are two ways to quickly make a .pdf out of this notebook for Gradescope submission.  Either:\n",
    " - Use File -> Download as PDF via LaTeX.  This will require your system path find a working install of a TeX compiler\n",
    " - Easier: Use File ->  Print Preview, and then Right-Click -> Print using your default browser and \"Print to PDF\"\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "**Shortcuts:**  [Problem 1](#p1) | [Problem 2](#p2) | [Problem 3](#p3) |\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a/ id='p1'></a>\n",
    "[Back to top](#top)\n",
    "# Problem 1 (Theory: minimal Permutations; 9 pts)\n",
    "\n",
    "Consider minhash values for a single column vector that contains 6 components/rows. Four of rows hold 0 and two hold 1. Consider taking all 6! = 720 possible distinct permutations of the six rows. When we choose a permutation of the rows and produce a minhash value for the column, we will use the number of the row, in the permuted order, that is the first with a 1.  Assume that we are 0-indexing when we return the minhash value for a permutation.  Use counting/probability/math in Markdown cells to demonstrate answers to the following, although you may check your work or logic with code/Python.\n",
    "\n",
    "### a) For exactly how many of the 720 permutations is the minhash value for the column a 5?  What proportion/probability is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are only 4 zeroes the first row to have a 1 can never be row 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) For exactly how many of the 720 permutations is the minhash value for the column a 4?  What proportion/probability is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$4!*2 = 48$ permutations that start with 4 zeroes$\\newline$ this has a probability of: $\\frac{2}{3}*\\frac{3}{5}*\\frac{1}{2}*\\frac{1}{3} = \\frac{1}{15}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) For exactly how many of the 720 permutations is the minhash value for the column a 2?  What proportion/probability is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$3!*4=24*3!=144$ permutations that start with 2 zeroes then a 1 \\$newline$ this has a probability of: $\\frac{2}{3}*\\frac{3}{5}*\\frac{1}{2}= \\frac{1}{5}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a/ id='p2'></a>\n",
    "[Back to top](#top)\n",
    "# Problem 2 (Permutations and Hashing; 6 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class we presented the result that hash functions can behave as **approximate** permutations.  We might, however, be interested in whether or not they are actually randomly selecting from all possible permutations, or if they might somehow be more limited and not \"choose\" some options.\n",
    "\n",
    "### a) Using Markdown cells and as much rigor as you can, prove or disprove the following claim:\n",
    "\n",
    "Given a characteristic matrix with prime $n$ rows, hash functions of the form $h(r)=ar+b \\mod n$ can provide each and every possible permutation of $n$ objects, where $0 < a, b < n$ are integers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is false. Take for example n=3, (0,1,2) are the rows. One potential permutation is (0,2,1) however, we will never achieve this permutation with the stated hash function form, as for 0 to end up as the first row, ar+b will have to equal 3 or a multiple of 3. Something that can't happen as b < n. B would have to be euqal to n or a multiple of n to recieve the permutation from the function. For example h(r) = 2r+3 mod 3 gives this permutation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### b) Using Markdown cells, argue in favor or in opposition to the following claim, using as much rigor as you can:\n",
    "Given a characteristic matrix with prime $n$ rows, hash functions of the form $h(r)=ar+b \\mod p$ can provide each and every possible permutation of $n$ objects, where $0 < a, b < p$ are integers and $p>n$ is prime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the ability to choose a prime mod larger than n, we will always be able to find has functions of the form $h(r) = ar+b mod p$ for each and every permutation of the matrix with n rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: As always with any proof that's a \"prove or disprove\" claim, try to convince yourself whether the claim is true or false by playing around with small objects, like $n=3$ or $n=5$.  Can you *constructively* make all possible permutations, or are some impossible?\n",
    "\n",
    "Try to be rigorous, but a well thought out written argument will suffice as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a/ id='p3'></a>\n",
    "[Back to top](#top)\n",
    "# Problem 3 (Applied Minhashing; 30 pts)\n",
    "\n",
    "In this problem we compare similarities of 6 documents available on http://www.gutenberg.org\n",
    "\n",
    "1) The first approximately 10000 characters of Alexander Dumas' *The Count of Monte Cristo*, written in French, in the file `countmc.txt`\n",
    " \n",
    " 2) The first approximately 10000 characters of Victor Hugo *Les Miserables*, written in French, in the file `lesmis.txt`\n",
    " \n",
    " 3) The first approximately 10000 characters of Jules Verne's *20,000 Leagues Under the Sea*, written in French and translated into English by Frederick Paul Walter, in the file `leagues.txt`\n",
    " \n",
    " 4) The first approximately 10000 characters of Kate Chopin's *The Awakening* in the file `awaken.txt`\n",
    " \n",
    " 5) The entirety of around 12000 characters of Kate Chopin's *Beyond the Bayou* in the file `BB.txt`\n",
    " \n",
    " 6) The first approximately 10000 characters of Homer's *The Odyssey*, translated into English by Samuel Butler, in the file `odyssey.txt`\n",
    "\n",
    " \n",
    "### a) Clean the 6 documents, scrubbing all punctuation, changes cases to lower case, and removing accent marks as appropriate.  \n",
    "\n",
    "\n",
    "**For this problem, you may import any text-based packages you desire to help wrangle the data.**  I recommend looking at some functions within `string` or the RegEx `re` packages.\n",
    "\n",
    "You can and probably should use functions in the string package such as `string.lower`, `string.replace`, etc.\n",
    "\n",
    "All 6 documents have been saved in UTF-8 encoding.\n",
    "\n",
    "After processing, you should have (at most) 27 unique characters in each book/section after cleaning, corresponding to white spaces and the 26 letters.  Print out the set of unique characters to ensure this.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UTF-8 text reading syntax, with new-line replace as white space\n",
    "with open('./data/countmc.txt', 'r', encoding=\"UTF-8\") as file:\n",
    "    countmc = file.read().replace('\\n', ' ')\n",
    "\n",
    "with open('./data/odyssey.txt', 'r', encoding=\"UTF-8\") as file:\n",
    "    odyssey = file.read().replace('\\n', ' ')\n",
    "\n",
    "with open('./data/BB.txt', 'r', encoding=\"UTF-8\") as file:\n",
    "    BB = file.read().replace('\\n', ' ')\n",
    "\n",
    "with open('./data/leagues.txt', 'r', encoding=\"UTF-8\") as file:\n",
    "    leagues = file.read().replace('\\n', ' ')\n",
    "\n",
    "with open('./data/lesmis.txt', 'r', encoding=\"UTF-8\") as file:\n",
    "    lesmis = file.read().replace('\\n', ' ')\n",
    "\n",
    "with open('./data/awaken.txt', 'r', encoding=\"UTF-8\") as file:\n",
    "    awaken = file.read().replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrub(string):\n",
    "    string = re.sub(r'[^\\w\\s]', '', string)\n",
    "    string = re.sub(r'[_\\d]', '', string)\n",
    "    string = unidecode.unidecode(string)\n",
    "    string = string.lower()\n",
    "    return(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "countmc = scrub(countmc)\n",
    "odyssey = scrub(odyssey)\n",
    "BB=scrub(BB)\n",
    "leagues=scrub(leagues)\n",
    "lesmis=scrub(lesmis)\n",
    "awaken=scrub(awaken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### b) Compute exact similarity scores between the documents.  Are these the expected results?\n",
    "\n",
    "Notes:\n",
    "- You should choose or explore different values of $k$ for your shingles and report the results for multiple values of $k$.  Which values create the largest **range** of similarity scores?\n",
    "- You may choose to shingle on words and create an n-gram model, but it is recommended you shingle on letters as described in class\n",
    "- You may construct your characteristic matrix or characteristic sets with or without hash functions (e.g. by using Python's `set` methods).  Note that choice of hash function should change heavily with $k$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shingle(k,docs):\n",
    "    shingles = dict.fromkeys(docs.keys(),[])\n",
    "    shingles.update({'unique':[]})\n",
    "    for i in docs:\n",
    "        temp = []\n",
    "        for j in range (len(docs[i])-k+1):\n",
    "            shingle = docs[i][j:j+k]\n",
    "            temp.append(shingle)\n",
    "            if shingle not in shingles['unique']:\n",
    "                shingles['unique'].append(shingle)\n",
    "        shingles.update({i:temp})\n",
    "    return shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {'odyssey':odyssey, 'countmc':countmc, 'BB':BB, 'leagues':leagues,'lesmis':lesmis,'awaken':awaken}\n",
    "docShingles = shingle(5,documents);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueShingles = docShingles.pop('unique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "shdf = pd.DataFrame.from_dict(docShingles, orient = 'index')\n",
    "shdf = shdf.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'odyssey': 1.0, 'countmc': 0.04652461151949381, 'BB': 0.4042890520694259, 'leagues': 0.40386432846791975, 'lesmis': 0.051176765147721584, 'awaken': 0.46512098815429787}\n",
      "{'odyssey': 0.06601941747572816, 'countmc': 1.0, 'BB': 0.08152536715620828, 'leagues': 0.10847422030872624, 'lesmis': 0.5174762143214823, 'awaken': 0.07775640376632581}\n",
      "{'odyssey': 0.5142718446601942, 'countmc': 0.07099655717874756, 'BB': 1.0, 'leagues': 0.4595190591200252, 'lesmis': 0.07050575863795694, 'awaken': 0.5495595828692923}\n",
      "{'odyssey': 0.3584466019417476, 'countmc': 0.07546291988461896, 'BB': 0.3201769025367156, 'leagues': 1.0, 'lesmis': 0.08002003004506761, 'awaken': 0.38432722486584997}\n",
      "{'odyssey': 0.06106796116504854, 'countmc': 0.4557550944449614, 'BB': 0.06809078771695594, 'leagues': 0.10311876509503308, 'lesmis': 1.0, 'awaken': 0.07836387567075023}\n",
      "{'odyssey': 0.41766990291262135, 'countmc': 0.05517818926211966, 'BB': 0.3983644859813084, 'leagues': 0.39535860548146595, 'lesmis': 0.0628943415122684, 'awaken': 1.0}\n"
     ]
    }
   ],
   "source": [
    "for doc1 in shdf.columns:\n",
    "    sims = {}\n",
    "    for doc2 in shdf.columns:\n",
    "        numer =0\n",
    "        s = pd.Series(shdf[doc2])\n",
    "        for i in shdf[doc1]:\n",
    "            if i!=None:\n",
    "                if np.any(s.isin([i])):\n",
    "                    numer+=1\n",
    "        denom = shdf[doc2].count()\n",
    "        sim = numer/denom\n",
    "        sims[doc2] = sim\n",
    "    print(sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Implement minhashing with 1000 hash functions on the 6 documents, checking your results against those in part b).\n",
    "\n",
    "- You may choose your own value of $p$ as the modulus of the hash functions.  You are encouraged to use the example code from the minhashing in class notebook to start you out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "shdfasnum = shdf.fillna(0)\n",
    "shdfasnum = shdfasnum.replace(to_replace = r'[\\D]', value=1,regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhash = 1000#more stuff from notebook 3\n",
    "Ahash = np.random.choice(range(0,10000), size=nhash)\n",
    "Bhash = np.random.choice(range(0,10000), size=nhash)\n",
    "Phash = 1091\n",
    "\n",
    "sigMatrix = np.full([nhash,len(shdfasnum.columns)],fill_value=np.inf)\n",
    "hash_vals = [0]*nhash\n",
    "for r in range(len(sigMatrix)):\n",
    "    for h in range(nhash):\n",
    "        hash_vals[h]=(Ahash[h]*r+Bhash[h])%Phash \n",
    "    for c in range(len(shdfasnum.columns)):\n",
    "        if(shdfasnum.iloc[r,c]==1):\n",
    "            for h in range(nhash):\n",
    "                if hash_vals[h] < sigMatrix[h,c]:\n",
    "                    sigMatrix[h,c] = hash_vals[h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(sigMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sigMatrix[:,0]==sigMatrix[:,1])/nhash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### d) Discussion:\n",
    "\n",
    "Can we detect expected differences here?  Are the two French documents most similar to each other?  Are the two documents by the same author, with the same theme, the most similar?  Is the French-to-English text the most similar English text when compared to the French texts? What kind of alternatives might have captured the structures between these texts?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really failed the min hashing part, I'm not sure what exactly is going wrong.The exact similarities however do show a higher similarity between the french documents, However the french-to-english text is most similar when compared to the french text. The books by the same author aren't as similar. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
